1. Ошибка теста: ложно-положительный результат (False Positive, FP).
   Это означает, что тест показал наличие заболевания, хотя на самом деле человек здоров.

2. Метрики классификации для матрицы ошибок TP = 5, TN = 90, FP = 10, FN = 5:
   - Точность (Accuracy): (TP + TN) / (TP + TN + FP + FN) = (5 + 90) / 100 = 0.95
   - Чувствительность (Sensitivity, Recall): TP / (TP + FN) = 5 / (5 + 5) = 0.5
   - Специфичность (Specificity): TN / (TN + FP) = 90 / (90 + 10) = 0.9
   - Полнота (Precision): TP / (TP + FP) = 5 / (5 + 10) = 0.33
   - F1-мера: 2 * (Precision * Recall) / (Precision + Recall) = 2 * (0.33 * 0.5) / (0.33 + 0.5) ≈ 0.38

3. Сравнение классификаторов:
   - Первый классификатор имеет очень высокую чувствительность, но низкую специфичность, что может указывать на много ложно-положительных результатов.
   - Второй классификатор имеет более сбалансированные показатели чувствительности и специфичности, что делает его более надежным для обнаружения обоих классов.
   Данные для классификации, вероятно, имеют различную структуру и распределение для каждого классификатора.

4. Гиперпараметры модели логистической регрессии:
   - Регуляризация (например, L1 и L2, параметры λ или C)
   - Метод оптимизации и его параметры (например, скорость обучения в градиентном спуске)
   - Число итераций для обучения модели
   - Функция потерь

5. Анализ весов модели логистической регрессии на данных Cars с числовыми признаками:
   Необходимо посмотреть на коэффициенты регрессии для каждого признака. Признак с наибольшим абсолютным значением коэффициента влияет на целевую переменную в наибольшей степени.

6. Значение функции сигмоиды σ(z) для z = 0.25:
   σ(0.25) = 1 / (1 + e^(-0.25)) ≈ 0.5596

7. Значение производной функции сигмоиды σ'(z) для z = -3:
   σ'(-3) = σ(-3) * (1 - σ(-3)) = (1 / (1 + e^3)) * (e^3 / (1 + e^3)) ≈ 0.0474

8. Классификация по логистической модели для z = 0.1 с порогом 0.6:
   Поскольку σ(0.1) ≈ 0.5244, что меньше порога 0.6, результат классификации будет отнесен к отрицательному классу.

9. Значение бинарной кросс-энтропии для предсказания y' = 0.1 и целевой переменной y = 1, где y' - это логистическая регрессия от y:*
   L(y, y') = -y * log(y') - (1 - y) * log(1 - y') = -1 * log(0.1) - (1 - 1) * log(0.9) ≈ 2.3026
